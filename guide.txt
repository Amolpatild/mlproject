# ML project

1. open the anaconda propmt---> change the dir
2. code .(open VS code)--> Terminal-->command prompt
3. create conda enviornment-->conda create -p venv python==3.8 -y
4. conda activate venv/
5. Create README.md
-->git add README.md
-->git commit -m "First Commit"
-->git branch -M main
-->git remote add origin https://github.com/Amolpatild/mlproject.git
-->git config --global user.name "John Doe"
-->git config --global user.email johndoe@example.com
-->git remote -v-->git push -u origin main
6. Create gitignore file in github-->add file-->create new file-->.gitignore-->type Python under the template and select it-->commit change .gitignore-->git pull

7. create setup.py and requirements.txt(write pandas,numpy, seaborn, -e .)
requirements.txt-->
pandas
numpy
seaborn
matplotlib
scikit-learn
catboost
xgboost
-e .# this is used to initialize the setup.py

8. in setup.py write code below:

from setuptools import find_packages,setup
from typing import List

HYPEN_E_DOT = '-e .'
def get_requirements(file_path:str)->List[str]:
    '''
    This fucntion returns list of enviornments
    '''

    requirements = []
    with open(file_path) as file_obj:
        requirements = file_obj.readlines()
        requirements = [req.replace('\n',' ') for req in requirements]
        if HYPEN_E_DOT in requirements:
            requirements.remove(HYPEN_E_DOT)
    return requirements

setup(

    name = 'mlproject',
    version='0.0.1',
    author='amol',
    author_email='patilamol011@gmail.com',
    packages=find_packages(),
    install_requires = get_requirements('requirements.txt'),

)


9. create folder src-->create file __init__.py-->this src folder will be the package
10. pip install -r requirements.txt
-->git add .
-->git status
-->git commit -m "The second commit"
-->git push -u origin main

11. create the component folder under the src folder --why-->it's require for the data ingenstion process.
-->create __init__.py file
-->create data_ingestion.py file
-->create data_trasnformation.py file
-->create model_trainer.py file

12. create pipeline folder
-->create __init__.py file
-->create prediction_pipeline.py file
-->create training_pipeline.py file

13. create the files under src folder
-->create utils.py file
-->create logger.py file
-->create exception.py file

14. write exception

import sys
from src.logger import  logging

def error_message_detail(error,error_detail:sys):
    _,_,exc_tb = error_detail.exc_info()
    file_name = exc_tb.tb_frame.f_code.co_filename
    error_message = "Error occured in python script name[{0}] line number[{1}] error message[{2}]".format(
        file_name,exc_tb.tb_lineno,str(error)
    )
    return error_message

class CustomException(Exception):
    def __init__(self, error_message,error_detail:sys):
        super().__init__(error_message)
        self.error_message = error_message_detail(error_message,error_detail=error_detail)

    def __str__(self):
        return self.error_message

**to test the file working or not******
                                            
if __name__ == "__main__":

    try:
        a = 1/0
    except Exception as e:
        logging.info("Logging has started")
        raise CustomException(e,sys)
****************************************

15. write logger
import logging
import os
from datetime import datetime

LOG_FILE = f"{datetime.now().strftime('%m_%d_%Y_%H_%M_%S')}.log"
logs_path = os.path.join(os.getcwd(),'logs',LOG_FILE)
os.makedirs(logs_path,exist_ok=True)

LOG_FILE_PATH = os.path.join(logs_path,LOG_FILE)

logging.basicConfig(
    filename= LOG_FILE_PATH,
    format="[ %(asctime)s ] %(lineno)d %(name)s - %(levelname)s - %(message)s",
    level=logging.INFO,
)

****to test the file working or not*****
if __name__ == "__main__":
    logging.info("Logging has started")
****************************************

remove the test part from logger and exeption files and push on git hub


16. create notebook folder
-->create data folder and add csv file and notebook files
-->run the notebook files 

17. write in data ingestion.py(components)

import os
import sys
from src.exception import CustomException
from src.logger import logging
import pandas as pd
from sklearn.model_selection import train_test_split
from dataclasses import dataclass

@dataclass
class DataIngestionConfig:
    train_data_path:str=os.path.join('artifacts','train.csv')
    test_data_path:str=os.path.join('artifacts','test.csv')
    raw_data_path:str=os.path.join('artifacts','data.csv')

class DataIngestion:
    def __init__(self):
        self.ingestion_config = DataIngestionConfig()

    def initiate_data_ingestion(self):
        logging.info("Enter the data ingestion method or component")
        try:
            df = pd.read_csv('notebook\data\stud.csv')
            logging.info("Read the data successfully")
            os.makedirs(os.path.dirname(self.ingestion_config.train_data_path),exist_ok=True)

            df.to_csv(self.ingestion_config.raw_data_path, index=False,header=True)
            logging.info("Train test split initiated")
            train_set, test_set = train_test_split(df,test_size=0.2,random_state= 42)

            train_set.to_csv(self.ingestion_config.train_data_path,index=False,header=True)
            test_set.to_csv(self.ingestion_config.test_data_path,index=False,header=True)

            logging.info("Ingestion of data compleated")

            return(
                self.ingestion_config.train_data_path,
                self.ingestion_config.test_data_path,
                

            )
        except Exception as e:
            raise CustomException(e,sys)
        

if __name__ == "__main__":
    obj = DataIngestion()
    obj.initiate_data_ingestion()




open the terminal --> python src/components/data_ingestion.py-->check artifacts are created and log file as well.

add .artificats line under the gitignore file in envrionment


18. data transformation

import sys
import os
from dataclasses import dataclass
from src.utils import save_object

import numpy as np
import pandas as pd
from sklearn.compose import ColumnTransformer
from sklearn.impute import SimpleImputer
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import OneHotEncoder
from sklearn.preprocessing import StandardScaler

from src.exception import CustomException
from src.logger import logging

@dataclass
class DataTransformationConfig:
    preprocessor_obj_file_path = os.path.join('artifacts','preprocessor.pkl')


class DataTransformation:
    def __init__(self):
        self.data_transformation_config = DataTransformationConfig()


    def get_data_transformer_object(self):

        '''
        This fucntion is responsible for data transformation
        '''
        try:
            numerical_colums = ['reading_score', 'writing_score']
            categorical_colums = [
                                'gender',
                                'race_ethnicity',
                                'parental_level_of_education',
                                'lunch',
                                'test_preparation_course'
                                ]
            numerical_pipeline = Pipeline(
                                steps=[
                                    ("imputer",SimpleImputer(strategy='median')),
                                    ('scaler',StandardScaler())
                                ]
            )
            categorical_pipline = Pipeline(
                                steps=[
                                    ('imputer',SimpleImputer(strategy='most_frequent')),
                                    ('one_hot_encoder',OneHotEncoder()),
                                    ('scaler',StandardScaler(with_mean=False))
                                ]
            )
            logging.info("Numberical columns standad scaling compleated")

            logging.info("Categorical columns endcoding compleated")

            preprocessor = ColumnTransformer(
                [
                ('num_pipeline',numerical_pipeline,numerical_colums),
                ('categorical_pipeline',categorical_pipline,categorical_colums)
                ]
            )
            
            return preprocessor
        
        except Exception as e:
            raise CustomException(e,sys)
        

    def initiate_data_transformation(self,train_path,test_path):
        try:
            train_df = pd.read_csv(train_path)
            test_df = pd.read_csv(test_path)

            logging.info('Read train and test data compleated')

            logging.info('Obtaining preprocessing object')

            preprocessing_object = self.get_data_transformer_object()

            target_column_name = 'math_score'
            numerical_colums = ['reading_score', 'writing_score']

            input_feature_train_df = train_df.drop(columns=[target_column_name],axis=1)
            target_feature_train_df = train_df[target_column_name]

            input_feature_test_df = test_df.drop(columns=[target_column_name],axis=1)
            target_feature_test_df = test_df[target_column_name]
            
            

            logging.info('Applying preprocessiong on the train and test data')

            input_feature_train_arr =preprocessing_object.fit_transform(input_feature_train_df)
            input_feature_test_arr =preprocessing_object.transform(input_feature_test_df)
            
            


            train_arr = np.c_[
                input_feature_train_arr,np.array(target_feature_train_df)
            ]
            test_arr = np.c_[input_feature_test_arr,np.array(target_feature_test_df)]

            logging.info('Saved the preprocessing object.')

            save_object(
                file_path = self.data_transformation_config.preprocessor_obj_file_path,
                obj = preprocessing_object
            )

            return (
                train_arr,
                test_arr,
                self.data_transformation_config.preprocessor_obj_file_path,
            )
        except Exception as e:
            raise CustomException(e,sys)

19. Write code in utils.py 

import os
import sys
from src.exception import CustomException
import dill

import numpy as np
import pandas as pd

def save_object(file_path,obj):
    try:
        dir_path = os.path.dirname(file_path)

        os.makedirs(dir_path,exist_ok=True)

        with open(file_path,'wb') as file_obj:
            dill.dump(obj,file_obj)

    except Exception as e:
        raise CustomException(e,sys)

====================================================

Add code at the end of data_ingestion.py

if __name__ == "__main__":
    obj = DataIngestion()
    train_data,test_data = obj.initiate_data_ingestion()
    data_transformation = DataTransformation()
    data_transformation.initiate_data_transformation(train_data,test_data)

20. write code in model_trainer.py


import os
import sys
from dataclasses import dataclass

from catboost import CatBoostRegressor
from sklearn.ensemble import (
    AdaBoostRegressor,
    GradientBoostingRegressor,
    RandomForestRegressor,
)
from sklearn.linear_model import LinearRegression
from sklearn.metrics import r2_score
from sklearn.neighbors import KNeighborsRegressor
from sklearn.tree import DecisionTreeRegressor
from xgboost import XGBRegressor

from src.exception import CustomException
from src.logger import logging

from src.utils import save_object,evaluate_models

@dataclass
class ModelTrainerConfig:
    trained_model_file_path=os.path.join("artifacts","model.pkl")

class ModelTrainer:
    def __init__(self):
        self.model_trainer_config=ModelTrainerConfig()


    def initiate_model_trainer(self,train_array,test_array):
        try:
            logging.info("Split training and test input data")
            X_train,y_train,X_test,y_test=(
                train_array[:,:-1],
                train_array[:,-1],
                test_array[:,:-1],
                test_array[:,-1]
            )
            models = {
                "Random Forest": RandomForestRegressor(),
                "Decision Tree": DecisionTreeRegressor(),
                "Gradient Boosting": GradientBoostingRegressor(),
                "Linear Regression": LinearRegression(),
                "XGBRegressor": XGBRegressor(),
                "CatBoosting Regressor": CatBoostRegressor(verbose=False),
                "AdaBoost Regressor": AdaBoostRegressor(),
            }
            params={
                "Decision Tree": {
                    'criterion':['squared_error', 'friedman_mse', 'absolute_error', 'poisson'],
                    # 'splitter':['best','random'],
                    # 'max_features':['sqrt','log2'],
                },
                "Random Forest":{
                    # 'criterion':['squared_error', 'friedman_mse', 'absolute_error', 'poisson'],
                 
                    # 'max_features':['sqrt','log2',None],
                    'n_estimators': [8,16,32,64,128,256]
                },
                "Gradient Boosting":{
                    # 'loss':['squared_error', 'huber', 'absolute_error', 'quantile'],
                    'learning_rate':[.1,.01,.05,.001],
                    'subsample':[0.6,0.7,0.75,0.8,0.85,0.9],
                    # 'criterion':['squared_error', 'friedman_mse'],
                    # 'max_features':['auto','sqrt','log2'],
                    'n_estimators': [8,16,32,64,128,256]
                },
                "Linear Regression":{},
                "XGBRegressor":{
                    'learning_rate':[.1,.01,.05,.001],
                    'n_estimators': [8,16,32,64,128,256]
                },
                "CatBoosting Regressor":{
                    'depth': [6,8,10],
                    'learning_rate': [0.01, 0.05, 0.1],
                    'iterations': [30, 50, 100]
                },
                "AdaBoost Regressor":{
                    'learning_rate':[.1,.01,0.5,.001],
                    # 'loss':['linear','square','exponential'],
                    'n_estimators': [8,16,32,64,128,256]
                }
                
            }

            model_report:dict=evaluate_models(X_train=X_train,y_train=y_train,X_test=X_test,y_test=y_test,
                                             models=models,param=params)
            
            ## To get best model score from dict
            best_model_score = max(sorted(model_report.values()))

            ## To get best model name from dict

            best_model_name = list(model_report.keys())[
                list(model_report.values()).index(best_model_score)
            ]
            best_model = models[best_model_name]

            if best_model_score<0.6:
                raise CustomException("No best model found")
            logging.info(f"Best found model on both training and testing dataset")

            save_object(
                file_path=self.model_trainer_config.trained_model_file_path,
                obj=best_model
            )

            predicted=best_model.predict(X_test)

            r2_square = r2_score(y_test, predicted)
            return r2_square
            



            
        except Exception as e:
            raise CustomException(e,sys)


21. add code in utils.py

import os
import sys
from src.exception import CustomException
import dill
import pickle
from sklearn.metrics import r2_score
from sklearn.model_selection import GridSearchCV

import numpy as np
import pandas as pd


def evaluate_models(X_train, y_train,X_test,y_test,models,param):
    try:
        report = {}

        for i in range(len(list(models))):
            model = list(models.values())[i]
            para=param[list(models.keys())[i]]

            gs = GridSearchCV(model,para,cv=3)
            gs.fit(X_train,y_train)

            model.set_params(**gs.best_params_)
            model.fit(X_train,y_train)

            #model.fit(X_train, y_train)  # Train model

            y_train_pred = model.predict(X_train)

            y_test_pred = model.predict(X_test)

            train_model_score = r2_score(y_train, y_train_pred)

            test_model_score = r2_score(y_test, y_test_pred)

            report[list(models.keys())[i]] = test_model_score

        return report

    except Exception as e:
        raise CustomException(e, sys)

=====================================================
add following code to the end of data_ingestion.py

if __name__ == "__main__":
    obj=DataIngestion()
    train_data,test_data=obj.initiate_data_ingestion()

    data_transformation=DataTransformation()
    train_arr,test_arr,_=data_transformation.initiate_data_transformation(train_data,test_data)

    modeltrainer=ModelTrainer()
    print(modeltrainer.initiate_model_trainer(train_arr,test_arr))

22. Prediction pipeline
-->create app.py in main directory

from flask import Flask,request,render_template
import numpy as np
import pandas as pd

from sklearn.preprocessing import StandardScaler
from src.pipeline.predict_pipeline import CustomData,PredictPipeline

application=Flask(__name__)

app=application

## Route for a home page

@app.route('/')
def index():
    return render_template('index.html') 

@app.route('/predictdata',methods=['GET','POST'])
def predict_datapoint():
    if request.method=='GET':
        return render_template('home.html')
    else:
        data=CustomData(
            gender=request.form.get('gender'),
            race_ethnicity=request.form.get('ethnicity'),
            parental_level_of_education=request.form.get('parental_level_of_education'),
            lunch=request.form.get('lunch'),
            test_preparation_course=request.form.get('test_preparation_course'),
            reading_score=float(request.form.get('writing_score')),
            writing_score=float(request.form.get('reading_score'))

        )
        pred_df=data.get_data_as_data_frame()
        print(pred_df)
        print("Before Prediction")

        predict_pipeline=PredictPipeline()
        print("Mid Prediction")
        results=predict_pipeline.predict(pred_df)
        print("after Prediction")
        return render_template('home.html',results=results[0])
    

if __name__=="__main__":
    app.run(host="0.0.0.0")        



========================================================
-->create templates folder under create index.html
<h1>Welcome to the home page</h1>


-->create templates folder under create home.html
<html>
<body>
    <div class="login">
       <h1>Student Exam Performance Indicator</h1>
   
       <form action="{{ url_for('predict_datapoint')}}" method="post">
        <h1>
            <legend>Student Exam Performance Prediction</legend>
        </h1>
        <div class="mb-3">
            <label class="form-label">Gender</label>
            <select class="form-control" name="gender" placeholder="Enter you Gender" required>
                <option class="placeholder" selected disabled value="">Select your Gender</option>
                <option value="male">
                    Male
                </option>
                <option value="female">
                    Female
                </option>
            </select>
        </div>
        <div class="mb-3">
            <label class="form-label">Race or Ethnicity</label>
            <select class="form-control" name="ethnicity" placeholder="Enter you ethnicity" required>
                <option class="placeholder" selected disabled value="">Select Ethnicity</option>
                <option value="group A">
                    Group A
                </option>
                <option value="group B">
                    Group B
                </option>
                <option value="group C">
                    Group C
                </option>
                <option value="group D">
                    Group D
                </option>
                <option value="group E">
                    Group E
                </option>
            </select>
        </div>
        <div class="mb-3">
            <label class="form-label">Parental Level of Education</label>
            <select class="form-control" name="parental_level_of_education"
                placeholder="Enter you Parent Education" required>
                <option class="placeholder" selected disabled value="">Select Parent Education</option>
                <option value="associate's degree">
                    associate's degree
                </option>
                <option value="bachelor's degree">
                    bachelor's degree
                </option>
                <option value="high school">
                    high school
                </option>
                <option value="master's degree">
                    master's degree
                </option>
                <option value="some college">
                    some college
                </option>
                <option value="some high school">
                    some high school
                </option>
            </select>
        </div>
        <div class="mb-3">
            <label class="form-label">Lunch Type</label>
            <select class="form-control" name="lunch" placeholder="Enter you Lunch" required>
                <option class="placeholder" selected disabled value="">Select Lunch Type</option>
                <option value="free/reduced">
                    free/reduced
                </option>
                <option value="standard">
                    standard
                </option>
            </select>
        </div>
        <div class="mb-3">
            <label class="form-label">Test preparation Course</label>
            <select class="form-control" name="test_preparation_course" placeholder="Enter you Course"
                required>
                <option class="placeholder" selected disabled value="">Select Test_course</option>
                <option value="none">
                    None
                </option>
                <option value="completed">
                    Completed
                </option>
            </select>
        </div>
        <div class="mb-3">
            <label class="form-label">Writing Score out of 100</label>
            <input class="form-control" type="number" name="reading_score"
                placeholder="Enter your Reading score" min='0' max='100' />
        </div>
        <div class="mb-3">
            <label class="form-label">Reading Score out of 100</label>
            <input class="form-control" type="number" name="writing_score"
                placeholder="Enter your Reading Score" min='0' max='100' />
        </div>
        <div class="mb-3">
            <input class="btn btn-primary" type="submit" value="Predict your Maths Score" required />
        </div>
    </form>
    <h2>
       THE  prediction is {{results}}
    </h2>
   <body>
</html>

23. paste the following code in pipeline_prediction.py

import sys
import pandas as pd
from src.exception import CustomException
from src.utils import load_object
import os


class PredictPipeline:
    def __init__(self):
        pass

    def predict(self,features):
        try:
            model_path=os.path.join("artifacts","model.pkl")
            preprocessor_path=os.path.join('artifacts','preprocessor.pkl')
            print("Before Loading")
            model=load_object(file_path=model_path)
            preprocessor=load_object(file_path=preprocessor_path)
            print("After Loading")
            data_scaled=preprocessor.transform(features)
            preds=model.predict(data_scaled)
            return preds
        
        except Exception as e:
            raise CustomException(e,sys)



class CustomData:
    def __init__(  self,
        gender: str,
        race_ethnicity: str,
        parental_level_of_education,
        lunch: str,
        test_preparation_course: str,
        reading_score: int,
        writing_score: int):

        self.gender = gender

        self.race_ethnicity = race_ethnicity

        self.parental_level_of_education = parental_level_of_education

        self.lunch = lunch

        self.test_preparation_course = test_preparation_course

        self.reading_score = reading_score

        self.writing_score = writing_score

    def get_data_as_data_frame(self):
        try:
            custom_data_input_dict = {
                "gender": [self.gender],
                "race_ethnicity": [self.race_ethnicity],
                "parental_level_of_education": [self.parental_level_of_education],
                "lunch": [self.lunch],
                "test_preparation_course": [self.test_preparation_course],
                "reading_score": [self.reading_score],
                "writing_score": [self.writing_score],
            }

            return pd.DataFrame(custom_data_input_dict)

        except Exception as e:
            raise CustomException(e, sys)

24. paste the following code under utils.py


def load_object(file_path):
    try:
        with open(file_path, "rb") as file_obj:
            return pickle.load(file_obj)

    except Exception as e:
        raise CustomException(e, sys)


===============================================
run python app.py file in terminal

http://127.0.0.1:5000/predictdata hit this url in endpoint